<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>The State-of-the-Art and Challenges of Data Stream Clustering Algorithms in Practice | Online clustering: algorithms, evaluation, metrics, application and benchmarking using River</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="The State-of-the-Art and Challenges of Data Stream Clustering Algorithms in Practice" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Tutorial presented at the 32nd International Joint Conference on Artificial Intelligence, 19th - 25th August 2023, Macau, S.A.R." />
<meta property="og:description" content="Tutorial presented at the 32nd International Joint Conference on Artificial Intelligence, 19th - 25th August 2023, Macau, S.A.R." />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="Online clustering: algorithms, evaluation, metrics, application and benchmarking using River" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="The State-of-the-Art and Challenges of Data Stream Clustering Algorithms in Practice" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","description":"Tutorial presented at the 32nd International Joint Conference on Artificial Intelligence, 19th - 25th August 2023, Macau, S.A.R.","headline":"The State-of-the-Art and Challenges of Data Stream Clustering Algorithms in Practice","name":"Online clustering: algorithms, evaluation, metrics, application and benchmarking using River","url":"http://localhost:4000/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=2e84e4e6a7702028d05f8e644818c6eaed1e8047">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'true', 'auto');
    ga('send', 'pageview');
  </script>



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->


  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> 


  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">The State-of-the-Art and Challenges of Data Stream Clustering Algorithms in Practice</h1>
      <h2 class="project-tagline">Tutorial presented at the 32<sup>nd</sup> International Joint Conference on Artificial Intelligence, 19<sup>th</sup> - 25<sup>th</sup> August 2023, Macau, S.A.R.</h2>
      
        <a href="./index.html" class="btn">Homepage</a>
        <a href="./related-materials.html" class="btn">Related materials</a>
      
      
        <a href="https://riverml.xyz/" class="btn">River's webpage</a>
        <a href="https://ijcai-23.org/" class="btn">IJCAI 23</a>
      
    </header>

    <main id="content" class="main-content" role="main">
      <style type="text/css">
  .image-left {
    display: block;
    margin-left: auto;
    margin-right: auto;
    float: right;
  }
</style>

<h1 id="practical-information">Practical information</h1>

<p>The agenda of the tutorial will be as follows:</p>

<ul>
  <li><strong>Place</strong>: Polytechnico di Torino</li>
  <li><strong>Time</strong>: Friday, September 22<sup>nd</sup> 2023, afternoon (GMT+1)</li>
</ul>

<h1 id="abstract">Abstract</h1>

<p>With significant advantages upon run time, resource usage, and complexity, online machine learning and stream clustering algorithms are playing a critical role in data science. Besides substantial resource advantages, these algorithms achieve a comparable performance to traditional batch machine learning methods. This tutorial will first surveys online machine learning and data stream clustering. With the emergence of fairness and interpretability, we will also discuss certain attempts in inducing a fair and interpretable machine learning model for data streams. We will then put the tutorial into a practical context with <code class="language-plaintext highlighter-rouge">River</code>, a Python library resulted from a merge between <code class="language-plaintext highlighter-rouge">Creme</code> and <code class="language-plaintext highlighter-rouge">scikit-multiflow</code>. We will also illustrate <code class="language-plaintext highlighter-rouge">River</code> as a go-to platform for online machine learning development by providing a guidance on how to integrate an algorithm with a clear workflow, alongside actual examples of past problems and solutions during the development process.</p>

<p>Besides, during this tutorial, state-of-the-art algorithms, associated core research approaches, and future directions of data stream clustering will be presented. Truly incremental clustering validity indices will also be mentioned as an important part of the stream clustering process and will be investigated thoroughly. Currently available metrics require the information of all past points, which is impractical for unlimited data streams. <code class="language-plaintext highlighter-rouge">River</code> is the first package to design and deploy such incremental indices.</p>

<p>Last but not least, the tutorial will demonstrate the use of <code class="language-plaintext highlighter-rouge">River</code> and the associated clustering module in real-world scenarios. From this, we propose methods of clustering configuration, hyper-parameter tuning, applications and settings for benchmarking using real-world problems and datasets. Preliminary benchmarking results will also be provided to showcase the advantages and consistency in the performance of implemented algorithms.</p>

<h1 id="two-sentence-tutorial-description">Two-sentence tutorial description</h1>

<p><em>(to be included into the conference registration brochure)</em></p>

<p>This tutorial provides an in-depth survey to online (data stream) machine learning, with an emphasis on fairness and interpretability, which is then later put into a practical context with \texttt{River}, a go-to Python library for the task. Moreover, data stream clustering problems will also be further rigorously investigated by mentioning state-of-the-art-algorithms, solutions for the implementation of incremental clustering validity indices, associated core research approaches, and future directions.</p>

<h1 id="two-paragraph-tutorial-description">Two-paragraph tutorial description</h1>

<p><em>(suitable for a web page overview, as per requested by the Call for Tutorials from IJCAI 23)</em></p>

<p>With significant advantages upon run time, resource usage, and complexity, online machine learning and stream clustering algorithms are playing a critical role in data science. Besides substantial resource advantages, these algorithms achieve a comparable performance to traditional batch machine learning methods. As such, the first part of this tutorial is devoted as a literature survey into the field, including a strong emphasis on fairness and interpretability, which is then put into a practical context with <code class="language-plaintext highlighter-rouge">River</code>, a go-to Python library resulted from a merge between <code class="language-plaintext highlighter-rouge">Creme</code> and <code class="language-plaintext highlighter-rouge">scikit-multiflow</code>.</p>

<p>Besides, we will also investigate the problem of data stream clustering rigorously with state-of-the-art algorithms, associated core research approaches and future directions. In parallel, we will also look into the design of incremental clustering validity indices, which is an important part of the benchmarking process. All preliminary results will be provided at the end to showcase the advantages and consistency in the performance of implemented algorithms within <code class="language-plaintext highlighter-rouge">River</code>.</p>

<h1 id="motivation">Motivation</h1>

<p>The motivations for this tutorial lie in the following points:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">River</code>, an open-source Python library for online machine learning, has become more and more popular. Being well-maintained and constantly developed, it has not only been used in academic research but also in industrial applications by top tech companies (including Harman Kardon, Bee2Beep, Lyft, etc.).</li>
  <li>Until now, the development of stream algorithms and truly incremental validity indices is quite scattered and uncentralized. Previously, algorithms are usually self-developed and self-maintained by the respective authors in various different programming languages, and a common framework is not available and widely known until <code class="language-plaintext highlighter-rouge">River</code> is generated. This causes a tremendous difficulty in testing and benchmarking currently available algorithms or facilitating further research/improvements. As such, we plan <code class="language-plaintext highlighter-rouge">River</code> to become not only a go-to library for any online machine learning task but also a pioneer framework for the implementation of any new algorithm within the field.</li>
  <li>Compared to other sections of online machine learning, although being an extremely important task, stream clustering particularly seems to receive less notice with very few thorough literature surveys, and even fewer works related to practical applications.</li>
  <li>Fairness and interpretability of online machine learning algorithms are of considerable importance, and significant efforts have also been put into the field, but they are not made widely aware of.</li>
</ul>

<h1 id="presenters-bibliography">Presenters’ bibliography</h1>

<p>The following authors will be in-person presenters, i.e., tutors who will attend IJCAI 2023 and present part of the tutorial: <strong>Jacob Montiel</strong>, <strong>Hoang-Anh Ngo</strong>, <strong>Minh-Huong Le-Nguyen</strong> and <strong>Albert Bifet</strong>.</p>

<p><img src="presenter-pics/jacob-montiel.jpg" alt="drawing" width="220" style="border-radius:60%" class="image-left" /></p>

<p><strong>Jacob Montiel</strong> is currently a Data Scientist in AWS Security. He is formerly a research fellow at the University of Waikato, New Zealand and Adjunct Researcher in the DIG Team at Télécom Paris, Institut Polytechnique de Paris, France and the core developer and maintainer of <code class="language-plaintext highlighter-rouge">River</code>.</p>

<p>His research interests are in the field of machine learning for evolving data streams. Prior to focusing on research, Jacob led the development work for onboard software for aircraft and engine’s prognostics at GE Aviation; working in the development of GE’s Brilliant Machines, part of the IoT and GE’s approach to Industrial Big Data.</p>

<p><em>Website:</em> <a href="https://jacobmontiel.github.io/">https://jacobmontiel.github.io/</a></p>

<p><em>Google Scholar profile:</em> <a href="https://scholar.google.com/citations?user=WOvISekAAAAJ&amp;hl=en">Jacob Montiel</a></p>

<p><br clear="left" /></p>

<p><img src="presenter-pics/hoang-anh.ngo.jpg" alt="drawing" width="220" style="border-radius:60%" class="image-left" /></p>

<p><strong>Hoang-Anh Ngo</strong> is currently supported by the AI Institute and the School of Computing and Mathematical Sciences, University of Waikato under an External Study Award (ESA) to support his research on <code class="language-plaintext highlighter-rouge">River</code>, the machine learning library in Python for data streams.</p>

<p>His research interests lies in the field of machine learning for evolving data stream, particularly in online clustering and classification algorithms. Previously, he joined the team of IT Specialists in COVID-19 task force, formed by the Ministry of Health of Vietnam as a Epidemiological Modelling Unit head.</p>

<p><em>Google Scholar profile:</em> <a href="https://scholar.google.com/citations?user=yelTvHAAAAAJ&amp;hl=en">Hoang-Anh Ngo</a></p>

<p><br clear="left" /></p>

<p><img src="presenter-pics/minh-huong.le-nguyen.jpg" alt="drawing" width="220" style="border-radius:60%" class="image-left" /></p>

<p><strong>Minh-Huong Le-Nguyen</strong> is a third-year doctoral student at LCTI, Télécom Paris, Institut Polytechnique de Paris in France. Her doctoral research focuses on the applications of machine learning on data streams to implement predictive maintenance in the railway industry. She received her Bachelor’s degree in Computer Science at University Pierre and Marie Curie (France) in 2013, then she graduated from Télécom Paris with a Master’s degree in Data Science in 2019.</p>

<p><em>ResearchGate profile:</em> <a href="https://www.researchgate.net/profile/Minh-Huong-Le-Nguyen">Minh-Huong Le-Nguyen</a></p>

<p><br clear="left" /></p>

<p><img src="presenter-pics/albert-bifet.jpg" alt="drawing" width="220" style="border-radius:60%" class="image-left" /></p>

<p><strong>Albert Bifet</strong> is a Professor of AI and the DIrector of the Te Ipu o te Mahara AI Institute  at University of Waikato, and Professor of Big Data at Data, Intelligence and Graphs (DIG) LTCI, Télécom Paris. Problems he investigate are motivated by large scale data, the Internet of Things (IoT), and Big Data Science. He co-leads the open source projects MOA (Massive On-line Analysis), Apache SAMOA (Scalable Advanced Massive Online Analysis) and StreamDM.</p>

<p><em>Website:</em> <a href="https://albertbifet.com/">https://albertbifet.com/</a></p>

<p><em>Google Scholar profile:</em> <a href="https://scholar.google.com/citations?user=UYvAL8EAAAAJ&amp;hl=en">Albert Bifet</a></p>

<h1 id="presenters-contact-information">Presenters’ contact information</h1>

<h3 id="jacob-montiel">Jacob Montiel</h3>

<p>  AI Institute, University of Waikato, New Zealand and LCTI, Télécom Paris, Institut Polytechnique de Paris, Frnace</p>

<p>  Email: <a href="mailto:jmontiel@waikato.ac.nz">jmontiel@waikato.ac.nz</a></p>

<h3 id="hoang-anh-ngo">Hoang-Anh Ngo</h3>

<p>  Artificial Intelligence Institute, University of Waikato, Hamilton, New Zealand</p>

<p>  Email: <a href="mailto:h.a.ngo@sms.ed.ac.uk">h.a.ngo@sms.ed.ac.uk</a></p>

<h3 id="minh-huong-le-nguyen">Minh-Huong Le Nguyen</h3>

<p>  LCTI, Télécom Paris, Institut Polytechnique de Paris, France</p>

<p>  Email: <a href="mailto:minh.lenguyen@telecom-paris.fr">minh.lenguyen@telecom-paris.fr</a></p>

<h3 id="albert-bifet">Albert Bifet</h3>

<p>  Artificial Intelligence Institute, University of Waikato, Hamilton, New Zealand and LCTI, Télécom Paris, Institut Polytechnique de Paris, France</p>

<p>  Email: <a href="mailto:abifet@waikato.ac.nz">abifet@waikato.ac.nz</a></p>

<h1 id="intended-audience">Intended audience</h1>

<p>The target audience of the tutorial includes any researchers and practitioners with interests in machine learning for big data, evolving data streams or IoT applications.</p>

<p>Basic knowledge with the Python programming language would be necessary. Apart from that, there will be no particular requirements or prerequisites on previous experience on data stream learning. However, either experience with traditional machine learning frameworks (<code class="language-plaintext highlighter-rouge">scikit-learn</code>, <code class="language-plaintext highlighter-rouge">keras</code>, <code class="language-plaintext highlighter-rouge">pytorch</code>, etc.) or previous interactions with online machine learning packages/tools, for example <code class="language-plaintext highlighter-rouge">MOA</code> (in Java), <code class="language-plaintext highlighter-rouge">stream</code> in <code class="language-plaintext highlighter-rouge">R</code>, <code class="language-plaintext highlighter-rouge">scikit-multiflow</code>, <code class="language-plaintext highlighter-rouge">Creme</code> or <code class="language-plaintext highlighter-rouge">River</code> in Python, would be beneficial.</p>

<p>For any developer who wants to contribute to <code class="language-plaintext highlighter-rouge">River</code> or use <code class="language-plaintext highlighter-rouge">River</code> to employ their own research work, a thorough understanding of <code class="language-plaintext highlighter-rouge">Git</code>, functionalities of <code class="language-plaintext highlighter-rouge">GitHub</code> (how to open a pull request, an issue, a discussion, Github Actions, etc.), code formatters in Python (<code class="language-plaintext highlighter-rouge">flake8</code>, <code class="language-plaintext highlighter-rouge">black</code>, <code class="language-plaintext highlighter-rouge">isort</code>, etc.) would be necessary.</p>

<h1 id="format-and-detailed-schedule">Format and detailed schedule</h1>

<p>The tutorial is intended to be of <strong>3.5 hours</strong> (half-day, consisting of <strong>two 1:45h slots</strong>), spread throughout <strong>3 sections</strong> with <strong>two 15-minute breaks</strong> between each section. The detailed outline of the tutorial is as follows:</p>

<ol>
  <li>Introduction to data stream (online) machine learning (<strong>1 hour</strong>):
    <ol>
      <li>What is online machine learning, and why do we need online machine learning?</li>
      <li>Differences, advantages and disadvantages of online machine learning compared to batch/traditional machine learning.</li>
      <li>Methods and interventions to induce fairness and interpretability in machine learning for streaming data in general.</li>
      <li>Introduction to <code class="language-plaintext highlighter-rouge">River</code>:
        <ol>
          <li>Its foundation as a merge between <code class="language-plaintext highlighter-rouge">Creme</code> and <code class="language-plaintext highlighter-rouge">scikit-multiflow</code>;</li>
          <li>Design principles;</li>
          <li>Major advantages of <code class="language-plaintext highlighter-rouge">River</code> towards its competitors;</li>
          <li>Major updates/improvements throughout the versions.</li>
        </ol>
      </li>
      <li>A brief guidance on how to develop/implement a model within <code class="language-plaintext highlighter-rouge">River</code>, along with demo and examples of past problems and solutions within the development process.</li>
      <li>Future maintenance and development orientation for <code class="language-plaintext highlighter-rouge">River</code>.</li>
    </ol>
  </li>
  <li>Online clustering algorithms and evaluation metrics (<code class="language-plaintext highlighter-rouge">1 hour 15 minutes</code>):
    <ol>
      <li>A literature survey on existing clustering algorithms, the general concepts, approaches and their evolution.</li>
      <li>Introduction to the state-of-the-art clustering algorithms implemented in <code class="language-plaintext highlighter-rouge">River</code> and their potential differences or advantages compared to previously implemented versions.</li>
      <li>How to improve accuracy in calculating micro-cluster centers and diameters through time using Welford’s algorithm.</li>
      <li>An investigation into currently available static validity indices, arising problems and motivation for the foundation of their truly incremental versions.</li>
      <li>A comparative survey on the expansion of incremental clustering validity indices, particularly among the most significant and widely used one that are adapted and integrated to <code class="language-plaintext highlighter-rouge">River</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">textClust</code> [Carnein <em>et al.</em>, 2017a], the first text clustering algorithm to be implemented in <code class="language-plaintext highlighter-rouge">River</code>.</li>
      <li>A brief introduction to research on fairness and interpretability of data stream clustering algorithms.</li>
      <li>Potential future research directions towards improvement in time and accuracy of stream clustering.</li>
    </ol>
  </li>
  <li>Use cases and benchmarking (<strong>45 minutes</strong>):
    <ol>
      <li>Practical applications.</li>
      <li>Comparison between online and traditional/batch clustering algorithms.</li>
      <li>Live visualization of stream algorithms and their results in synthetic and real-life scenarios.</li>
      <li>Motivation, setting and system requirements for conducting benchmarking.</li>
      <li>Tutorial on benchmarking using the River package and the associated available <code class="language-plaintext highlighter-rouge">git</code> repository and terminal.</li>
      <li>Preliminary benchmarking results.</li>
    </ol>
  </li>
</ol>

<h1 id="brief-outline">Brief outline</h1>

<h2 id="introduction-to-data-stream-machine-learning">Introduction to data stream machine learning</h2>

<p>This first part is intended to provide the motivation and necessity of online stream learning. As a matter of fact, traditional machine learning methods can not deal with an particularly large amount of data with limited resources and time constrains, which means that there is an urgent need for specific data stream machine learning methods with comparable results.</p>

<p>Besides providing insights on advantages and disadvantages of online machine learning, we will also provide an introduction to <code class="language-plaintext highlighter-rouge">River</code>, a Python library aimed to become a go-to toolkit for this purpose with numerous advantages and features towards its open source competitors. Not only will we present <code class="language-plaintext highlighter-rouge">River</code> as a tool, we will also provide a detailed guide on how to contribute to <code class="language-plaintext highlighter-rouge">River</code> or utilize <code class="language-plaintext highlighter-rouge">River</code> to facilitate participants’ own research works.</p>

<p>To conclude this section,  we present the latest trends in research for fairness and interpretability of stream machine learning models. Having to handle an unlimited amount of data while having to maintain the accuracy under concept drifts, the research for a fair and interpretable AI is interesting, yet much more demanding compared to that of traditional machine learning models.</p>

<h2 id="a-literature-survey-on-online-clustering-algorithms-and-metrics">A literature survey on online clustering algorithms and metrics</h2>

<p>This part will first start with an extensive survey on online clustering algorithms. First, we will start with the development from the first algorithms that introduced the concept of micro-clusters/macro-clusters and online/offline phases (BIRCH/CluStream), then to the evolution based on different approaches. These approaches include either distance-based, grid-based, model-based or projected, two-phase, type of time windows (damped, sliding, landmark or pyramidal), or the use of medoids/centroids. Besides interpreting these approaches, respective algorithms and their implementations within <code class="language-plaintext highlighter-rouge">River</code> are also introduced, including KMeans, DenStream, DBStream, STREAMKMeans and EvoStream.</p>

<p>With the emerging research on fairness and interpretability of AI, we will also discuss certain attempts in inducing a fair and interpretable stream clustering algorithm, including</p>

<ul>
  <li>The first attempts for a fair K-Means algorithm by Schmidt et al. (2018) [Schmidt <em>et al.</em>, 2018] or fair k-Center algorithm by Bera et al. (2022) [Bera <em>et al.</em>, 2022] have been introduced.</li>
  <li>Intepretable multiple data stream clustering with clipped stream representation has also been proposed by Laurinec and Lucká (2019) [Laurinec and Lucká, 2018].</li>
</ul>

<p>From this, we will discuss their effectiveness and later on how to apply these certain approaches for a broader family of clustering algorithms.</p>

<p>Finally, one aspect of online clustering algorithms that are usually neglected is the use of incremental validation metrics. Currently, apart from <code class="language-plaintext highlighter-rouge">River</code>, there is no tool/package that facilitates the use of truly incremental metrics, i.e. metrics that only use the summary statistics and the latest observation instead of having to use information of all passed points, which is impractical in stream learning. As such, in this part, we will also focus on the construction and comparison between these metrics, and also how to apply them in analyzing clustering algorithms’ performances when put into practice.</p>

<h2 id="practical-applications-and-benchmarking-using-the-clustering-module-of-river">Practical applications and benchmarking using the clustering module of <code class="language-plaintext highlighter-rouge">River</code></h2>

<p>The final part serves as a practical demonstration on the usage of <code class="language-plaintext highlighter-rouge">River</code> and the associated clustering module in real-life scenarios.</p>

<p>First, a brief demonstration of <code class="language-plaintext highlighter-rouge">River</code> will be presented and its essential functionalities will also be compared with respective traditional/batch machine learning algorithms in terms of performance, memory and time usage to prove that although online methods takes up less resources, they have the ability to obtain a similar accuracy.</p>

<p>The next part will be dedicated to stream clustering algorithm’s benchmarking work. The setting, system requirement, benchmarking method and hyper-parameter tuning will all be discussed.</p>

<p>Last but not least, preliminary benchmarking results with dedicated datasets will also be provided to exhibit the advantages and consistency in the performance of implemented algorithms.</p>

<h1 id="type-of-support-material-to-be-supplied-to-attendees">Type of support material to be supplied to attendees</h1>

<p>Participants will receive the following support material:</p>

<ul>
  <li>Presentation slides;</li>
  <li>PDF versions (including results) of any quizzes and surveys within the tutorial;</li>
  <li>All Jupyter notebooks and demos executed within and/or related to the tutorial.</li>
</ul>

<p>Apart from the printed materials, the electronic version will all be freely, publicly available on the dedicated tutorial’s website.</p>

<h1 id="list-of-previous-offerings-of-the-tutorial-and-relationship-with-them">List of previous offerings of the tutorial and relationship with them</h1>

<h2 id="list-of-previous-offerings-of-the-tutorial">List of previous offerings of the tutorial</h2>

<p>There has been two previous offerings of similar tutorials on the topic at highly-ranked conferences, including:</p>

<ul>
  <li>First offering:
    <ul>
      <li><strong>Title:</strong> Online Clustering: Algorithms, Evaluation, Metrics, Applications and Benchmarking using <code class="language-plaintext highlighter-rouge">River</code>.</li>
      <li><strong>Conference:</strong> The 26th Pacific - Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2022).</li>
      <li><strong>Number of participants:</strong>} Unknown. Due to the COVID-19 prevention measures and time differences, the tutorial is presented online with a pre-recorded video.</li>
    </ul>
  </li>
  <li>Second offering:
    <ul>
      <li><strong>Title:</strong> Online Clustering: Online Clustering: Algorithms, Evaluation, Metrics, Applications and Benchmarking [Montiel <em>et al.</em>, 2022].</li>
      <li><strong>Conference:</strong> The 28th ACM SIGKDD Cofnerence on Knowledge Discovery and Data Mining (KDD ‘22).</li>
      <li><strong>Content:</strong> Publicly available within \href<a href="https://hoanganhngo610.github.io/river-clustering.kdd.2022/">the tutorial’s website</a> and <a href="https://dl.acm.org/doi/10.1145/3534678.3542600">the conference’s proceedings</a>.</li>
      <li><strong>Number of participants:</strong> Approximately 50 participants.</li>
    </ul>
  </li>
</ul>

<h2 id="relationship-to-previous-editions">Relationship to previous editions</h2>

<h3 id="similarities">Similarities</h3>

<p>This tutorial will preserve its strong points from previous editions by</p>
<ul>
  <li>providing a deep, thorough literature survey of state-of-the-art stream clustering algorithms and future research directions; and</li>
  <li>allowing participants to have essential understanding of online learning, put under a practical point of view by <code class="language-plaintext highlighter-rouge">River</code>. Moreover, they will also be provided with interactive  demonstration that simulates real-life scenarios.</li>
</ul>

<h3 id="differences">Differences</h3>

<p>The main differences of this tutorial compared to its previous versions are:</p>

<ul>
  <li>First and foremost, this tutorial will be more developer-oriented. This means that, apart from providing guidance and use cases <code class="language-plaintext highlighter-rouge">River</code>, the authors also provide a detailed picture of the developing process and how to contribute/develop a user’s own algorithm within the ecosystem, along with actual problems and solutions during the development process. This is expected to potentially solve the problem of scattered and unorganized implementation of currently available stream clustering algorithms.</li>
  <li>On top of that, a clear development and maintenance orientation under the form of a public roadmap will also be provided. This can be considered as one of the most crucial parts in the development of any open-source projects.</li>
  <li>The tutorial will also tackle the problems and provide detailed insights as a literature review of fairness and interpretability of online machine learning algorithms in general and stream clustering algorithms in particular. This part is intended to address a comment on the tutorial offering at KDD’22. Moreover, this will also be the first tutorial to ever conduct a survey into this aspect of online machine learning.</li>
  <li>This tutorial will also be the first to analyze the implementation strategy of truly incremental clustering metrics in <code class="language-plaintext highlighter-rouge">River</code>, which are not available in any other online machine learning tools/packages.</li>
  <li>Apart from providing a guidance on how to conduct benchmarking with <code class="language-plaintext highlighter-rouge">River</code>, preliminary results for comparison will also be provided. This work has just been completed recently and were not provided within any previous editions of this tutorial.</li>
  <li>The tutorial will also introduce a starting solution to new research pathways in stream clustering algorithms:
    <ul>
      <li>Text clustering algorithms (despite the fact that previously, text clustering can be done with an indirect approach, using Term Frequency - Inverse Document Frequency (TF-IDF) [Rajaraman and Ullman, 2011] with an arbitrary numerical stream clustering algorithm;</li>
      <li>Improvement in accuracy of calculating micro-clusters’ centers and diameters using Welford’s algorithm [Chan <em>et al.</em>, 1982] instead of cluster feature vectors.</li>
    </ul>
  </li>
</ul>

<h1 id="strategies-to-enhance-audience-and-interactivity">Strategies to enhance audience and interactivity</h1>

<p>Since it is intended to be a mix between a lecture-style and a practical-style tutorial, the authors intend to imply various strategies to enhance interaction and interest, including:</p>

<ul>
  <li>Including various small Question and Answers sessions in the tutorial to enhance speaker - audience interaction, ideally once after every finished section;</li>
  <li>Interactive quizzes or surveys (e.g. quizzes hosted on <a href="https://www.kahoot.it">kahoot</a> will also be useful in attracting attendance and making the atmosphere more relaxed, while, at the same time, they can also make sure that the audience can understand the content conveyed;</li>
  <li>Using interactive tools like Jupyter notebooks with <code class="language-plaintext highlighter-rouge">Holoviews</code> or <code class="language-plaintext highlighter-rouge">Plotly</code> to represent real-time results for the purpose of visualisation;</li>
  <li>Switching presenters on-the-go, not necessarily after each section, will significantly increase attendees’ attention towards the tutorial;</li>
  <li>Instead of pre-filling all code snippets, a lot of tasks within the demo will be left blank so that users can try to have a practical experience with all parts, either within or after the tutorial. Having all tools, packages and frameworks open-source (including <code class="language-plaintext highlighter-rouge">River</code> and the associated demo repository) is also a plus in facilitating this practice.</li>
  <li>Organizing small coding challenges or competitions. Since the main theme of the practical part of this tutorial is live visualisation and benchmarking, a certain level of competitiveness would create an energetic and enjoyable environment.</li>
</ul>

<h1 id="ethical-statement">Ethical statement</h1>

<p>There are no ethical concerns related to the topic of this tutorial.</p>

<h1 id="related-materials">Related materials</h1>

<p>For all related materials, including presentation slides, demos, source code, related papers and any other piece of information, please visit <a href="./related-materials.html">this page</a>.</p>

<h1 id="citation">Citation</h1>

<p>TBA</p>

<h1 id="references">References</h1>

<p>[Ackermann et al., 2012] Marcel R. Ackermann, Marcus Martens, Christoph Raupach, Kamil Swierkot, Christiane  Lammersen, and Christian Sohler. Streamkm++: A clustering algorithm for data streams. <em>ACM J. Exp. Algorithmics</em>, 17, May 2012.</p>

<p>[Aggarwal and Reddy, 2016] Charu C. Aggarwal and Chandan K. Reddy. <em>Data Clustering Algorithms and Applications</em>. Chapman and Hall/CRC, 2016.</p>

<p>[Aggarwal et al., 2003] Charu C. Aggarwal, Jiawei Han, Jianyong Wang, and Phillip S. Yu. A framework for clustering evolving data streams. In <em>Proceedings of the 29th International Conference on Very Large Data Bases - Volume 29</em>, VLDB ’03, pages 81–92, Berlin, Germany, 2003. VLDB Endowment.</p>

<p>[Amini et al., 2014] Amineh Amini, Teh Ying Wah, and Hadi Saboohi. On density-based data streams clustering algorithms: A survey. <em>Journal of Computer Science and Technology</em>, 29(1):116–141, January 2014.</p>

<p>[Bera et al., 2022] Suman K. Bera, Syamantak Das, Sainyam Galhotra, and Sagar Sudhir Kale. Fair k-center clustering in mapreduce and streaming settings. In <em>Proceedings of the ACM Web Conference 2022</em>, WWW ’22, page 1414–1422, New York, NY, USA, 2022. Association for Computing Machinery.</p>

<p>[Bifet et al., 2018] Albert Bifet, Ricard Gavald`a, Geoff Holmes, and Bernhard Pfahringer. <em>Machine Learning for Data Streams: with Practical Examples in MOA</em>. The MIT Press, Cambridge, MA, USA, 2018.</p>

<p>[Cao et al., 2006] Feng Cao, Martin Estert, Weining Qian, and Aoying Zhou. Density-based clustering over an evolving data stream with noise. In <em>Proceedings of the 2006 SIAM International Conference on Data Mining (SDM)</em>, pages 328–339, Philadelphia, PA, USA, 2006. Society for Industrial and Applied Mathematics (SIAM).</p>

<p>[Carnein and Trautmann, 2019] Matthias Carnein and Heike Trautmann. Optimizing data stream representation: An extensive survey on stream clustering algorithms. <em>Business &amp; Information Systems Engineering</em>, 61:277–297, 2019.</p>

<p>[Carnein et al., 2017a] Matthias Carnein, Dennis Assenmacher, and Heike Trautmann. Stream clustering of chat messages with applications to twitch streams. In <em>Proceedings of the 36th International Conference on Conceptual Modeling (ER ’17)</em>, pages 79–88. Springer International Publishing, 2017.</p>

<p>[Carnein et al., 2017b] Matthias Carnein, Assenmacher Dennis, and Heike Trautmann. An empirical comparison of stream clustering algorithms. In <em>Proceedings of the Computing Frontiers Conference, CF’17</em>, pages 361––366, New York, NY, USA, 2017. Association for Computing Machinery.</p>

<p>[Chan et al., 1982] T.F. Chan, G. H. Golub, and R. J. LeVeque. Updating formulae and a pairwise algorithm for computing sample variances. In <em>COMSTATS 1982 5th Symposium</em>. Physica, Heidenberg, 1982.</p>

<p>[Chen and Tu, 2007] Yixin Chen and Li Tu. Density-based clustering for real-time stream data. In <em>Proceedings of the 13th ACM SIGKKDD internaional conference on Knowledge discovery and data mining</em>, KDD ’07, pages 133–142, New York, NY, USA, August 2007. Association for Computing Machinery.</p>

<p>[Ghesmoune et al., 2016] Mohammed Ghesmoune, Mustapha Lebbah, and Hanene Azzag. State-of-the-art on clustering data streams. <em>Big Data Analytics</em>, 1(1):13, 2016.</p>

<p>[Halford et al., 2019] Max Halford, Geoffrey Bolmier, Raphael Sourty, Robin Vaysse, and Adil Zouitine. <code class="language-plaintext highlighter-rouge">creme</code>, a Python library for online machine learning, 2019.</p>

<p>[Hashler and Bolanos, 2016] Michael Hashler and MatthewBolanos. Clustering data streams based on shared density between micro-clusters. <em>IEEE Transactions on Knowledge and Data Engineering</em>, 28(6):1449–1461, 2016.</p>

<p>[Javed et al., 2020] Ali Javed, Byung Suk Lee, and Donna M. Rizzo. A benchmark study on time series clustering. <em>Machine Learning with Applications</em>, 1:100001, September 2020.</p>

<p>[Laurinec and Lucká, 2018] Peter Laurinec and Mária Lucká. Interpretable multiple data streams clustering with clipped streams representation for the improvement of electricity consumption forecasting. <em>Data Mining and Knowledge Discovery</em>, 33:413–445, 2018.</p>

<p>[Mansalis et al., 2018] Stratos Mansalis, Eirini Ntoutsi, Nikos Pelekis, and Yannis Theodoridis. An evaluation of data stream clustering algorithm. <em>Statistical Analysis and Data Mining: The ASA Data Science Journal</em>, 11:167–187, 2018.</p>

<p>[Montiel et al., 2018] Jacob Montiel, Jesse Read, Albert Bifet, and Talel Abdessalem. Scikit-multiflow: A multi-output streaming framework. <em>Journal of Machine Learning Research</em>, 19(72):1–5, 2018.</p>

<p>[Montiel et al., 2021] Jacob Montiel, Max Halford, Saulo Martiello Mastelini, Geoffrey Bolmier, Raphael Sourty, Robin Vaysse, Adil Zouitine, Heitor Murilo Gomes, Jesse Read, Talel Abdessalem, and Albert Bifet. River: machine learning for streaming data in python. <em>Journal of Machine Learning Research</em>, 22:1–8, April 2021.</p>

<p>[Montiel et al., 2022] Jacob Montiel, Hoang-Anh Ngo, Minh-Huong Le-Nguyen, and Albert Bifet. Online clustering: Algorithms, evaluation, metrics, applications and benchmarking. In <em>Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, KDD ’22, page 4808–4809, New York, NY, USA, 2022. Association for Computing Machinery.</p>

<p>[O’Callaghan et al., 2002] L. O’Callaghan, N. Mishra, A. Meyerson, S. Guha, and R. Motwani. Streaming-data algorithms for high-quality clustering. In <em>Proceedings 18th International Conference on Data Engineering</em>, pages 685–694, San Jose, CA, USA, August 2002. IEEE.</p>

<p>[Rajaraman and Ullman, 2011] Anand Rajaraman and Jeffrey David Ullman. <em>Data Mining</em>, page 1–17. Cambridge University Press, 2011.</p>

<p>[Schmidt et al., 2018] Melanie Schmidt, Chris Schwiegelshohn, and Christian Sohler. Fair coresets and streaming algorithms for fair k-means clustering. CoRR, abs/1812.10854, 2018.</p>

<p>[Silva et al., 2020] Leonardo Enzo Brito Da Silva, Niklas Max Melton, and Donald C. Wunsch. Incremental cluster validity indices for online learning of hard partitions: Extensions and comparative study. <em>IEEE Access</em>, 8:22025–22047, January 2020.</p>


      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/hoanganhngo610/stream-clustering.ijcai.2023">This tutorial's website</a> is maintained by <a href="https://github.com/hoanganhngo610">Hoang Anh Ngo</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </main>
  </body>
</html>
